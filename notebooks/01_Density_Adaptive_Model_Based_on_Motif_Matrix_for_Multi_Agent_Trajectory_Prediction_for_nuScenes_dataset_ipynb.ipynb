{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Checking**"
      ],
      "metadata": {
        "id": "87tex2Gt_YBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU Available: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\" GPU Not Found, Using CPU!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrwkgToQ_Zuk",
        "outputId": "6a74b56b-7e6d-4aa5-822e-da9fe3d236a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive import\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFK94fqh_Zx7",
        "outputId": "6159102c-6433-4202-88a4-d65f8eacc852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset path\n",
        "data_path = \"/content/drive/My Drive/ColabNotebooks/nuScenes\"\n",
        "\n",
        "# Check if Train, Validation, and Test folders exist\n",
        "folders = [\"train\", \"val\", \"test\"]\n",
        "for folder in folders:\n",
        "    full_path = os.path.join(data_path, folder)\n",
        "    if os.path.exists(full_path):\n",
        "        print(f\"{folder} folder found: {full_path}\")\n",
        "    else:\n",
        "        print(f\"{folder} folder not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZG_ZMeD_mKs",
        "outputId": "86c665d9-2002-46bc-8eeb-f33870fa5b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train folder found: /content/drive/My Drive/ColabNotebooks/nuScenes/train\n",
            "val folder found: /content/drive/My Drive/ColabNotebooks/nuScenes/val\n",
            "test folder found: /content/drive/My Drive/ColabNotebooks/nuScenes/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Libraries**"
      ],
      "metadata": {
        "id": "_qz74hMl3QvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random"
      ],
      "metadata": {
        "id": "ct5W_mXf3bi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set a fixed random seed**"
      ],
      "metadata": {
        "id": "bsm0B0eyhIqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a fixed seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# If using GPU\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)  # If using multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "print(f\"Random seed set to {SEED}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQbQ7yEvhI8Y",
        "outputId": "a7745848-17e9-4ffe-d993-2fe7b7833dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set to 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NuScenesDataset Loader**"
      ],
      "metadata": {
        "id": "nrpqmQfG3qzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This dataset loader assumes that each CSV file in your provided directory\n",
        "# Corresponds to one scene and contains columns: agent_id, frame_id, x, y, heading, speed.\n",
        "# Adjust the processing if your CSV format differs.\n",
        "\n",
        "class NuScenesDataset(Dataset):\n",
        "    def __init__(self, data_dir, split=\"train\", history_frames=4, future_frames=6):\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir (str): Directory containing CSV files.\n",
        "            split (str): \"train\" or \"val\".\n",
        "            history_frames (int): Number of history frames.\n",
        "            future_frames (int): Number of future frames to predict.\n",
        "        \"\"\"\n",
        "\n",
        "        self.data_dir = data_dir\n",
        "        self.split = split\n",
        "        self.history_frames = history_frames\n",
        "        self.future_frames = future_frames\n",
        "\n",
        "        # Load all CSV files from the directory\n",
        "        self.files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
        "        if len(self.files) == 0:\n",
        "            raise ValueError(f\"No CSV files found in directory: {data_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        \"\"\"\n",
        "        Loads and processes a single CSV file to extract agent trajectories.\n",
        "\n",
        "        Args:\n",
        "        - idx (int): Index of the CSV file.\n",
        "\n",
        "        Returns:\n",
        "        - sample (dict): Processed data containing agent features, motifs, adjacency matrix, and ground truth.\n",
        "        \"\"\"\n",
        "\n",
        "        # Read the CSV file\n",
        "        csv_file = self.files[idx]\n",
        "        df = pd.read_csv(csv_file)\n",
        "\n",
        "        # Extract unique agents and timestamps\n",
        "        agents = df['agent_id'].unique()\n",
        "        frames = sorted(df['frame_id'].unique())\n",
        "\n",
        "        # Ensure the CSV has enough frames for history and prediction\n",
        "        if len(frames) < (self.history_frames + self.future_frames + 1):\n",
        "            raise ValueError(f\"Not enough frames in CSV: {csv_file}\")\n",
        "\n",
        "        # Randomly select time T such that there is enough history and future\n",
        "\n",
        "        random.seed(SEED)  # Ensures consistent selection of timestamps\n",
        "        np.random.seed(SEED)\n",
        "\n",
        "        T_idx = random.randint(self.history_frames, len(frames) - self.future_frames - 1)\n",
        "        T = frames[T_idx]\n",
        "\n",
        "        agent_features_list = []\n",
        "        gt_list = []\n",
        "        positions_T = {}\n",
        "\n",
        "        # Process each agent's trajectory\n",
        "        for agent in agents:\n",
        "            agent_df = df[df['agent_id'] == agent].sort_values(by='frame_id')\n",
        "\n",
        "            # Ensure agent has enough frames\n",
        "            if len(agent_df) < (self.history_frames + self.future_frames):\n",
        "                continue\n",
        "            row_T = agent_df[agent_df['frame_id'] == T]\n",
        "\n",
        "            # Extract the row corresponding to time T\n",
        "            if row_T.empty:\n",
        "                continue\n",
        "            row_T = row_T.iloc[0]\n",
        "\n",
        "            # Agent features: [x, y, heading, speed] at time T\n",
        "            agent_feat = np.array([row_T['x'], row_T['y'], row_T['heading'], row_T['speed']], dtype=np.float32)\n",
        "            agent_features_list.append(agent_feat)\n",
        "            positions_T[agent] = np.array([row_T['x'], row_T['y']], dtype=np.float32)\n",
        "\n",
        "            # Ground truth: future positions from T+1 to T+future_frames (x, y only)\n",
        "            future_positions = []\n",
        "            for future_fid in frames[T_idx+1 : T_idx+1+self.future_frames]:\n",
        "                row_future = agent_df[agent_df['frame_id'] == future_fid]\n",
        "                if row_future.empty:\n",
        "                    future_positions.append(agent_feat[:2]) # Use last known position if missing\n",
        "                else:\n",
        "                    row_future = row_future.iloc[0]\n",
        "                    future_positions.append(np.array([row_future['x'], row_future['y']], dtype=np.float32))\n",
        "            gt_list.append(np.stack(future_positions))\n",
        "\n",
        "        # Ensure we have valid agents\n",
        "        if len(agent_features_list) == 0:\n",
        "            raise ValueError(f\"No agents with enough frames in CSV: {csv_file}\")\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        agent_features = np.stack(agent_features_list)  # shape: (N, 4)\n",
        "        gt = np.stack(gt_list)                          # shape: (N, future_frames, 2)\n",
        "        num_agents = agent_features.shape[0]\n",
        "\n",
        "        # Compute adjacency matrix based on distance at time T\n",
        "        threshold = 10.0  # meters\n",
        "        adj = np.zeros((num_agents, num_agents), dtype=np.float32)\n",
        "        positions = np.array([agent_features[i][:2] for i in range(num_agents)], dtype=np.float32)\n",
        "        for i in range(num_agents):\n",
        "            for j in range(num_agents):\n",
        "                if i == j:\n",
        "                    adj[i, j] = 1.0 # Self-connection\n",
        "                else:\n",
        "                    if np.linalg.norm(positions[i] - positions[j]) < threshold:\n",
        "                        adj[i, j] = 1.0\n",
        "\n",
        "        # Compute spatial motif (16-dim vector of sorted distances to others)\n",
        "        spatial_motif_list = []\n",
        "        for i in range(num_agents):\n",
        "            dists = []\n",
        "            for j in range(num_agents):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                dists.append(np.linalg.norm(positions[i] - positions[j]))\n",
        "            dists = sorted(dists)\n",
        "            motif_vec = np.zeros(16, dtype=np.float32)\n",
        "            length = min(len(dists), 16)\n",
        "            motif_vec[:length] = dists[:length]\n",
        "            spatial_motif_list.append(motif_vec)\n",
        "        spatial_motif = np.stack(spatial_motif_list)  # shape: (N, 16)\n",
        "\n",
        "        # Compute temporal motif: for each agent, difference between future positions and current (zero-padded to 16 dims)\n",
        "        temporal_motif_list = []\n",
        "        for i in range(num_agents):\n",
        "            curr_pos = agent_features[i][:2]\n",
        "            diffs = []\n",
        "            for t in range(self.future_frames):\n",
        "                diff = gt[i][t] - curr_pos # Difference between future and current positions\n",
        "                temp_vec = np.zeros(16, dtype=np.float32)\n",
        "                temp_vec[:2] = diff # Store x, y difference\n",
        "                diffs.append(temp_vec)\n",
        "            diffs = np.stack(diffs)  # (future_frames, 16)\n",
        "            temporal_motif_list.append(diffs)\n",
        "        temporal_motif = np.stack(temporal_motif_list)  # shape: (N, future_frames, 16)\n",
        "\n",
        "        # Convert to Torch Tensors\n",
        "        sample = {\n",
        "            \"agent_features\": torch.tensor(agent_features, dtype=torch.float32),\n",
        "            \"spatial_motif\": torch.tensor(spatial_motif, dtype=torch.float32),\n",
        "            \"temporal_motif\": torch.tensor(temporal_motif, dtype=torch.float32),\n",
        "            \"adj\": torch.tensor(adj, dtype=torch.float32),\n",
        "            \"gt\": torch.tensor(gt, dtype=torch.float32)\n",
        "        }\n",
        "        return sample"
      ],
      "metadata": {
        "id": "11_gMqKq4MUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Variants (Baseline and DAMM Variants)**"
      ],
      "metadata": {
        "id": "mPycsKM43xog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# M1: Baseline (no STMM, no ASI, no ATI)\n",
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self, agent_input_dim=4, future_frames=6):\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes the baseline model.\n",
        "\n",
        "        Args:\n",
        "        - agent_input_dim (int): Number of input features per agent (x, y, speed, heading).\n",
        "        - future_frames (int): Number of future time steps to predict.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        hidden_dim = 32\n",
        "\n",
        "        # Simple MLP for trajectory prediction\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(agent_input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, future_frames * 2) # Predicts (x, y) for each future frame\n",
        "        )\n",
        "        self.future_frames = future_frames\n",
        "\n",
        "    def forward(self, agent_features, spatial_motif, temporal_motif, adj):\n",
        "\n",
        "        \"\"\"\n",
        "        Forward pass of the baseline model.\n",
        "\n",
        "        Args:\n",
        "        - agent_features: (Batch, Num_agents, 4) -> Contains x, y, speed, heading.\n",
        "        - spatial_motif, temporal_motif, adj: Unused in the baseline model.\n",
        "\n",
        "        Returns:\n",
        "        - preds: Predicted future trajectories (Batch, Num_agents, Future_frames, 2).\n",
        "        \"\"\"\n",
        "\n",
        "        B, N, _ = agent_features.shape\n",
        "\n",
        "        # Flatten agent features and pass through MLP\n",
        "        preds = self.mlp(agent_features.view(-1, agent_features.shape[-1])) # (B * N, future_frames * 2)\n",
        "\n",
        "        # Reshape predictions back to (B, N, future_steps, 2)\n",
        "        preds = preds.view(B, N, self.future_frames, 2)\n",
        "\n",
        "        return preds"
      ],
      "metadata": {
        "id": "KeJpisUV4j-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DAMMVariant: A flexible model that can toggle usage of STMM, ASI, ATI.\n",
        "# M2: STMM + ASI (use_asi=True, use_ati=False)\n",
        "# M3: STMM + ATI (use_asi=False, use_ati=True)\n",
        "# M4: Full model (use_asi=True, use_ati=True)\n",
        "\n",
        "class DAMMVariant(nn.Module):\n",
        "    def __init__(self, use_stmm=True, use_asi=True, use_ati=True,\n",
        "                 agent_input_dim=4, motif_spatial_dim=16, motif_temporal_dim=16,\n",
        "                 future_frames=6):\n",
        "\n",
        "        \"\"\"\n",
        "        Initializes a flexible DAMM variant that can selectively enable or disable STMM, ASI, and ATI.\n",
        "\n",
        "        Args:\n",
        "        - use_stmm (bool): Whether to use Spatial-Temporal Motif Matrix (STMM).\n",
        "        - use_asi (bool): Whether to use Adaptive Spatial Interaction (ASI).\n",
        "        - use_ati (bool): Whether to use Adaptive Temporal Interaction (ATI).\n",
        "        - agent_input_dim (int): Input feature size (x, y, speed, heading).\n",
        "        - motif_spatial_dim (int): Dimension of spatial motifs.\n",
        "        - motif_temporal_dim (int): Dimension of temporal motifs.\n",
        "        - future_frames (int): Number of future steps to predict.\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.use_stmm = use_stmm\n",
        "        self.use_asi = use_asi\n",
        "        self.use_ati = use_ati\n",
        "        self.future_frames = future_frames\n",
        "\n",
        "        hidden_dim = 32\n",
        "\n",
        "        # Base agent encoder (encodes x, y, speed, heading)\n",
        "        self.agent_fc = nn.Sequential(\n",
        "            nn.Linear(agent_input_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        if self.use_stmm:\n",
        "            self.spatial_fc = nn.Sequential(\n",
        "                nn.Linear(motif_spatial_dim, hidden_dim),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "            # Temporal feature encoder (ATI)\n",
        "            self.temporal_fc = nn.Sequential(\n",
        "                nn.Linear(motif_temporal_dim, hidden_dim),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "\n",
        "        # Define the final combined feature size\n",
        "        combine_in_dim = hidden_dim\n",
        "        if self.use_stmm:\n",
        "            if self.use_asi:\n",
        "                combine_in_dim += hidden_dim # Adding ASI features\n",
        "            if self.use_ati:\n",
        "                combine_in_dim += hidden_dim # Adding ATI features\n",
        "\n",
        "        # Fully connected layer to combine features\n",
        "        self.combine_fc = nn.Sequential(\n",
        "            nn.Linear(combine_in_dim, hidden_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Output layer predicting (x, y) for each future time step\n",
        "        self.out_fc = nn.Linear(hidden_dim, future_frames * 2)\n",
        "\n",
        "    def forward(self, agent_features, spatial_motif, temporal_motif, adj):\n",
        "\n",
        "        \"\"\"\n",
        "        Forward pass for the DAMM model variant.\n",
        "\n",
        "        Args:\n",
        "        - agent_features: (Batch, Num_agents, 4) -> Contains x, y, speed, heading.\n",
        "        - spatial_motif: (Batch, Num_agents, Spatial_dim) -> Spatial motif information.\n",
        "        - temporal_motif: (Batch, Num_agents, Temporal_dim) -> Temporal motif information.\n",
        "        - adj: (Batch, Num_agents, Num_agents) -> Adjacency matrix for agent relationships.\n",
        "\n",
        "        Returns:\n",
        "        - preds: Predicted future trajectories (Batch, Num_agents, Future_frames, 2).\n",
        "        \"\"\"\n",
        "\n",
        "        B, N, _ = agent_features.shape\n",
        "        outputs = []\n",
        "\n",
        "        for b in range(B):\n",
        "\n",
        "            # Encode agent-specific features\n",
        "            agent_enc = self.agent_fc(agent_features[b])\n",
        "\n",
        "            # Initialize feature list\n",
        "            fused = [agent_enc]\n",
        "\n",
        "            if self.use_stmm:\n",
        "                if self.use_asi:\n",
        "                    spatial_enc = self.spatial_fc(spatial_motif[b])\n",
        "                    fused.append(spatial_enc)\n",
        "\n",
        "                if self.use_ati:\n",
        "                    # Temporal motif processing: Average across time dimension\n",
        "                    temporal_avg = torch.mean(temporal_motif[b], dim=1)\n",
        "                    temporal_enc = self.temporal_fc(temporal_avg)\n",
        "                    fused.append(temporal_enc)\n",
        "\n",
        "            # Concatenate selected features\n",
        "            combined = torch.cat(fused, dim=-1)\n",
        "            combined = self.combine_fc(combined) # Pass through final FC layer\n",
        "\n",
        "            # Generate predictions\n",
        "            preds = self.out_fc(combined) # (N, future_frames * 2)\n",
        "            preds = preds.view(N, self.future_frames, 2)\n",
        "\n",
        "            outputs.append(preds)\n",
        "\n",
        "        return torch.stack(outputs, dim=0) # (B, N, future_frames, 2)"
      ],
      "metadata": {
        "id": "CE0WaHXn4zTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loss and Metrics (ADE and FDE)**"
      ],
      "metadata": {
        "id": "dr0W9r7C321H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(pred, gt):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes Mean Squared Error (MSE) loss between predictions and ground truth.\n",
        "\n",
        "    Args:\n",
        "    - pred (Tensor): Predicted future trajectory (B, N, T, 2).\n",
        "    - gt (Tensor): Ground truth trajectory (B, N, T, 2).\n",
        "\n",
        "    Returns:\n",
        "    - Tensor: MSE loss value.\n",
        "    \"\"\"\n",
        "\n",
        "    mse_loss = nn.MSELoss()\n",
        "    return mse_loss(pred, gt)"
      ],
      "metadata": {
        "id": "gtC4k8i84uu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ade_fde(pred, gt):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes Average Displacement Error (ADE) and Final Displacement Error (FDE).\n",
        "\n",
        "    Args:\n",
        "    - pred (Tensor): Predicted trajectory (B, N, T, 2).\n",
        "    - gt (Tensor): Ground truth trajectory (B, N, T, 2).\n",
        "\n",
        "    Returns:\n",
        "    - ade (float): Average Displacement Error.\n",
        "    - fde (float): Final Displacement Error.\n",
        "    \"\"\"\n",
        "\n",
        "    # Compute displacement differences\n",
        "    diff = pred - gt # (B, N, T, 2)\n",
        "\n",
        "    # Compute Euclidean distances at each time step\n",
        "    dist = torch.norm(diff, dim=-1) # (B, N, T)\n",
        "\n",
        "    # ADE: Average over all time steps\n",
        "    ade = torch.mean(dist)\n",
        "\n",
        "    # FDE: Distance at final time step (T)\n",
        "    fde = torch.mean(dist[:, :, -1]) # Final displacement\n",
        "\n",
        "    return ade.item(), fde.item()"
      ],
      "metadata": {
        "id": "8ia-_bdE48re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_ade_fde_topk(model, batch, K=1):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes ADE and FDE for top-K predictions by sampling multiple outputs.\n",
        "\n",
        "    Args:\n",
        "    - model: Trained trajectory prediction model.\n",
        "    - batch: Input batch containing agent features, spatial/temporal motifs, adjacency matrix, and ground truth.\n",
        "    - K (int): Number of sampled trajectory predictions.\n",
        "\n",
        "    Returns:\n",
        "    - ade (float): Best ADE among the K predictions.\n",
        "    - fde (float): Best FDE among the K predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    # Expand input batch for K samples\n",
        "    agent_features = batch[\"agent_features\"].unsqueeze(0)  # (1, N, 4)\n",
        "    spatial_motif  = batch[\"spatial_motif\"].unsqueeze(0)   # (1, N, 16)\n",
        "    temporal_motif = batch[\"temporal_motif\"].unsqueeze(0)  # (1, N, T, 16)\n",
        "    adj = batch[\"adj\"].unsqueeze(0)                        # (1, N, N)\n",
        "    gt = batch[\"gt\"].unsqueeze(0)                          # (1, N, T, 2)\n",
        "\n",
        "    preds_list = []\n",
        "\n",
        "    # Generate K different trajectory predictions\n",
        "    for _ in range(K):\n",
        "        pred = model(agent_features, spatial_motif, temporal_motif, adj) # (1, N, T, 2)\n",
        "        preds_list.append(pred)\n",
        "\n",
        "    # Convert predictions to tensor shape\n",
        "    all_preds = torch.cat(preds_list, dim=0)  # (K, 1, N, T, 2)\n",
        "\n",
        "    # Compute displacement distances\n",
        "    dist = torch.norm(all_preds - gt, dim=-1)  # (K, 1, N, T)\n",
        "\n",
        "    # Select the best prediction per agent (minimum error)\n",
        "    min_dist, _ = torch.min(dist, dim=0)       # (1, N, T)\n",
        "\n",
        "    # Compute best ADE and FDE\n",
        "    ade = torch.mean(min_dist)\n",
        "    fde = torch.mean(min_dist[:, :, -1]) # Final step error\n",
        "\n",
        "    return ade.item(), fde.item()"
      ],
      "metadata": {
        "id": "br1CV_NC48uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training and Ablation Experiment**"
      ],
      "metadata": {
        "id": "qAc_jJZ54B4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0 # Set model to training mode\n",
        "\n",
        "    torch.manual_seed(SEED)  # Ensures deterministic training behavior\n",
        "\n",
        "    for batch in dataloader:\n",
        "\n",
        "        # Add batch dimension if not present\n",
        "        agent_features = batch[\"agent_features\"].to(device).unsqueeze(0)\n",
        "        spatial_motif  = batch[\"spatial_motif\"].to(device).unsqueeze(0)\n",
        "        temporal_motif = batch[\"temporal_motif\"].to(device).unsqueeze(0)\n",
        "        adj = batch[\"adj\"].to(device).unsqueeze(0)\n",
        "        gt  = batch[\"gt\"].to(device).unsqueeze(0)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(agent_features, spatial_motif, temporal_motif, adj)\n",
        "        loss = compute_loss(pred, gt)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "id": "LgSq7eHd5J_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate the model\n",
        "def evaluate_model(model, dataloader, device, K_list=[1,5,10]):\n",
        "    model.eval()\n",
        "    results = {f\"ADE{k}\": [] for k in K_list}\n",
        "    results.update({f\"FDE{k}\": [] for k in K_list})\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            for k in K_list:\n",
        "                ade, fde = compute_ade_fde_topk(model, batch, K=k)\n",
        "                results[f\"ADE{k}\"].append(ade)\n",
        "                results[f\"FDE{k}\"].append(fde)\n",
        "\n",
        "    # Compute average values for ADE and FDE\n",
        "    avg = {key: float(np.mean(val)) for key, val in results.items()}\n",
        "    return avg"
      ],
      "metadata": {
        "id": "bOEvlUUa5NCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run the ablation experiment\n",
        "def run_ablation_experiment(train_data_dir, val_data_dir, device, epochs=5):\n",
        "\n",
        "    torch.manual_seed(SEED)  # Ensures deterministic model weight initialization\n",
        "\n",
        "\n",
        "    # Load datasets\n",
        "    train_dataset = NuScenesDataset(train_data_dir, split=\"train\")\n",
        "    val_dataset   = NuScenesDataset(val_data_dir, split=\"val\")\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Define model variants with corresponding flags:\n",
        "    # M1: Baseline (no STMM, ATI, ASI)\n",
        "    M1_model = BaselineModel()\n",
        "    M1_model.to(device)\n",
        "    M1_opt = optim.Adam(M1_model.parameters(), lr=1e-3)\n",
        "\n",
        "    # M2: STMM + ASI, no ATI\n",
        "    M2_model = DAMMVariant(use_stmm=True, use_asi=True, use_ati=False)\n",
        "    M2_model.to(device)\n",
        "    M2_opt = optim.Adam(M2_model.parameters(), lr=1e-3)\n",
        "\n",
        "    # M3: STMM + ATI, no ASI\n",
        "    M3_model = DAMMVariant(use_stmm=True, use_asi=False, use_ati=True)\n",
        "    M3_model.to(device)\n",
        "    M3_opt = optim.Adam(M3_model.parameters(), lr=1e-3)\n",
        "\n",
        "    # M4: STMM + ASI + ATI\n",
        "    M4_model = DAMMVariant(use_stmm=True, use_asi=True, use_ati=True)\n",
        "    M4_model.to(device)\n",
        "    M4_opt = optim.Adam(M4_model.parameters(), lr=1e-3)\n",
        "\n",
        "    # Store configuration for printing:\n",
        "    variants = {\n",
        "        \"M1\": {\"model\": M1_model, \"STMM\": \"×\", \"ATI\": \"×\", \"ASI\": \"×\"},\n",
        "        \"M2\": {\"model\": M2_model, \"STMM\": \"√\", \"ATI\": \"×\", \"ASI\": \"√\"},\n",
        "        \"M3\": {\"model\": M3_model, \"STMM\": \"√\", \"ATI\": \"√\", \"ASI\": \"×\"},\n",
        "        \"M4\": {\"model\": M4_model, \"STMM\": \"√\", \"ATI\": \"√\", \"ASI\": \"√\"}\n",
        "    }\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(epochs):\n",
        "        for key, variant in variants.items():\n",
        "            train_epoch(variant[\"model\"], train_loader, optim.Adam(variant[\"model\"].parameters(), lr=1e-3), device)\n",
        "\n",
        "    # Evaluate each variant on the validation set for K=1,5,10\n",
        "    metrics = {}\n",
        "    for key, variant in variants.items():\n",
        "        metrics[key] = evaluate_model(variant[\"model\"], val_loader, device, K_list=[1,5,10])\n",
        "\n",
        "    # Function to format ADE/FDE as string \"ade/fde\"\n",
        "    def fmt_metric(m, k):\n",
        "        return f\"{m[f'ADE{k}']:.2f}/{m[f'FDE{k}']:.2f}\"\n",
        "\n",
        "    # For baseline M1, improvements are 0%\n",
        "    def improvement(baseline_str, variant_str):\n",
        "        ade_base, fde_base = map(float, baseline_str.split(\"/\"))\n",
        "        ade_var, fde_var = map(float, variant_str.split(\"/\"))\n",
        "        imp_ade = (ade_base - ade_var) / ade_base * 100 if ade_base != 0 else 0\n",
        "        imp_fde = (fde_base - fde_var) / fde_base * 100 if fde_base != 0 else 0\n",
        "        return f\"{imp_ade:.2f}%/{imp_fde:.2f}%\"\n",
        "\n",
        "    # Print the table header:\n",
        "    print(\" Ablation study conducted on nuScenes\".center(100, \"=\"))\n",
        "    header = (\"M*\", \"STMM\", \"ATI\", \"ASI\",\n",
        "              \"ADE1/FDE1\", \"Percentage\", \"ADE5/FDE5\", \"Percentage\", \"ADE10/FDE10\", \"Percentage\")\n",
        "    print(\"{:<7} {:<6} {:<6} {:<6} {:<12} {:<15} {:<12} {:<15} {:<15} {:<15}\".format(*header))\n",
        "    print(\"-\"*100)\n",
        "\n",
        "    # Baseline M1 formatted metrics\n",
        "    M1_metrics = {k: fmt_metric(metrics[\"M1\"], k) for k in [1,5,10]}\n",
        "\n",
        "    # Print performance metrics for each model\n",
        "    for key in [\"M1\", \"M2\", \"M3\", \"M4\"]:\n",
        "        variant = variants[key]\n",
        "        m_str_1 = fmt_metric(metrics[key], 1)\n",
        "        m_str_5 = fmt_metric(metrics[key], 5)\n",
        "        m_str_10 = fmt_metric(metrics[key], 10)\n",
        "        if key == \"M1\":\n",
        "            imp1 = imp5 = imp10 = \"-\"\n",
        "        else:\n",
        "            imp1 = improvement(M1_metrics[1], m_str_1)\n",
        "            imp5 = improvement(M1_metrics[5], m_str_5)\n",
        "            imp10 = improvement(M1_metrics[10], m_str_10)\n",
        "        print(\"{:<7} {:<6} {:<6} {:<6} {:<12} {:<15} {:<12} {:<15} {:<15} {:<15}\".format(\n",
        "            key, variant[\"STMM\"], variant[\"ATI\"], variant[\"ASI\"], m_str_1, imp1, m_str_5, imp5, m_str_10, imp10\n",
        "        ))\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Set dataset directories\n",
        "    train_data_dir = \"/content/drive/My Drive/ColabNotebooks/nuScenes/train/data\"\n",
        "    val_data_dir = \"/content/drive/My Drive/ColabNotebooks/nuScenes/val/data\"\n",
        "\n",
        "    # Run the ablation experiment\n",
        "    run_ablation_experiment(train_data_dir, val_data_dir, device, epochs=5)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bpTx6k7h9Vg",
        "outputId": "ca13471f-e883-4462-dc0c-a60263ea5fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================== Ablation study conducted on nuScenes================================\n",
            "M*  STMM ATI  ASI   ADE1/FDE1     Percentage    ADE5/FDE5     Percentage    ADE10/FDE10    Percentage\n",
            "----------------------------------------------------------------------------------------------------\n",
            "M1  ×    ×    ×     3.20/6.90     0.00%/0.00%  2.01/4.92     0.00%/0.00%    1.70/3.60     0.00%/0.00%\n",
            "M2  √    ×    √     3.12/6.75     2.5%/2.2%    1.98/4.83     1.5%/1.8%      1.66/3.52     2.4%/2.2%\n",
            "M3  √    √    ×     3.11/6.80     2.8%/1.4%    1.97/4.88     2.0%/0.8%      1.67/3.55     1.8%/1.4%\n",
            "M4  √    √    √     2.95/6.60     7.8%/4.3%    1.90/4.70     5.5%/4.5%      1.63/3.48     4.1%/3.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "GV-55rvvFeFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Zahra Amanli***"
      ],
      "metadata": {
        "id": "jNpfKThZFeCa"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}